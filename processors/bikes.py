"""Processing steps dedicated to the bikes GBFS feed."""

from __future__ import annotations

from functools import partial
from pathlib import Path
from typing import List

import pandas as pd

from .base import PipelineResult, ProcessingContext, QualityReport, run_pipeline

REQUIRED_COLUMNS: List[str] = [
    "id_compteur",
    "nom_compteur",
    "sum_counts",
    "date",
]

NUMERIC_COLUMNS = ["sum_counts"]
DATE_COLUMNS = ["date", "installation_date"]


def load_raw(path: Path) -> pd.DataFrame:
    """Load the raw JSON Lines payload generated by the Lambda."""

    return pd.read_json(path, orient="records", lines=True)


def _flatten_results(df: pd.DataFrame) -> pd.DataFrame:
    if "results" not in df.columns:
        return df

    exploded = df.explode("results", ignore_index=True)
    if exploded.empty:
        return pd.DataFrame(columns=REQUIRED_COLUMNS)

    records = pd.json_normalize(exploded["results"])
    return records


def _standardise_columns(df: pd.DataFrame) -> pd.DataFrame:
    rename_map = {
        "id": "id_site",
        "name": "nom_site",
        "sum_counts": "compteur_total",
    }
    frame = df.rename(columns=rename_map)
    return frame


def _cast_types(df: pd.DataFrame) -> pd.DataFrame:
    frame = df.copy()
    for column in NUMERIC_COLUMNS:
        if column in frame.columns:
            frame[column] = pd.to_numeric(frame[column], errors="coerce")
    for column in DATE_COLUMNS:
        if column in frame.columns:
            frame[column] = pd.to_datetime(frame[column], errors="coerce")
    return frame


def _quality_required_columns(df: pd.DataFrame, report: QualityReport) -> None:
    missing = [col for col in REQUIRED_COLUMNS if col not in df.columns]
    if missing:
        report.add(f"error: missing expected columns {missing}")
    else:
        report.add("ok: required columns present")


def _quality_missing_dates(df: pd.DataFrame, report: QualityReport) -> None:
    if "date" in df.columns and df["date"].isna().any():
        report.add("warning: some rows have an invalid `date`")


def _enrich_metadata(df: pd.DataFrame, context: ProcessingContext) -> pd.DataFrame:
    frame = df.copy()
    if context.input_path:
        date_folder = context.input_path.parent.name
        frame["ingestion_date"] = date_folder
        frame["source_file"] = context.input_path.name
    frame["source"] = context.source
    return frame


def process(path: Path) -> PipelineResult:
    """Execute the full pipeline for a single bikes JSON file."""

    raw_df = load_raw(path)
    context = ProcessingContext(source="bikes", input_path=path)
    return run_pipeline(
        df=raw_df,
        cleaning=(
            _flatten_results,
            _standardise_columns,
            _cast_types,
        ),
        quality_checks=(
            _quality_required_columns,
            _quality_missing_dates,
        ),
        enrichments=(
            partial(_enrich_metadata, context=context),
        ),
        context=context,
    )
